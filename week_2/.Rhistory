install.packages("ggplot2")
---
require(stats)
# simplest form of fitting a first-order model to these data
fm1 <- nls(demand ~ A*(1-exp(-exp(lrc)*Time)), data = BOD,
start = c(A = 20, lrc = log(.35)))
coef(fm1)
fm1
# using the plinear algorithm
fm2 <- nls(demand ~ (1-exp(-exp(lrc)*Time)), data = BOD,
start = c(lrc = log(.35)), algorithm = "plinear", trace = TRUE)
# using a self-starting model
fm3 <- nls(demand ~ SSasympOrig(Time, A, lrc), data = BOD)
summary(fm3)
BOD
iris
ggplot(data = iris, aes(x= Petal.Length)) +
geom_bar(fill = "lightyellow", colour = "red")
library(ggplot2)
ggplot(data = iris, aes(x= Petal.Length)) +
geom_bar(fill = "lightyellow", colour = "red")
ggplot(data = iris, aes(x= Petal.Length)) +
geom_bar(fill = "lightyellow", colour = "red")
#單變數:連續型
ggplot(data = iris,aes(x = Petal.Length)) + geom_histogram()
`stat_bin()` using `bins = 30`. Pick better value with `binwidth`
#雙變數:連續V.S.連續
ggplot(data = iris,aes(x = Sepal.Length, y = Sepal.Width)) + geom_point()
#雙變數:離散V.S.連續
ggplot(iris,aes(x = Petal.Length, y = Petal.Width)) + geom_boxplot(colour = black)
#雙變數:離散V.S.連續
ggplot(iris,aes(x = Petal.Length, y = Petal.Width)) + geom_boxplot(colour = "black")
#單變數:連續型
ggplot(data = iris,aes(x = Petal.Length)) + geom_histogram()
#雙變數:離散V.S.連續
ggplot(iris,aes(x = Petal.Length, y = Petal.Width)) + geom_boxplot(colour = "black")
ggplot(data = iris, aes(x= Petal.Length)) + geom_bar(fill = "lightyellow", colour = "black")
rm(list=ls(all.names = TRUE))
docs <- tm_map(docs, toSpace, "‧")
mapply(pttTestFunction,
URL = URL, filename = filename)
wordcloud(freq$seg, freq$Freq,
min.freq = 2, random.order = F,
color = brewer.pal(8, "Dark2"))
source('pttTestFunction.R')
pttTestFunction(URL[1], filename[1])
getContent <- function(x) {
url  = paste0("https://www.ptt.cc", x)
tag  = html_node(read_html(url), 'div#main-content.bbs-screen.bbs-content')
text = toUTF8(html_text(tag))
}
allText
pttTestFunction <- function(URL, filename)
{
#URL   = "https://www.ptt.cc/bbs/NTUcourse/index.html"
html  = read_html(URL)
title = html_nodes(html, "a")
href  = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)),
href = href)
data = data[-c(1:10),]
getContent <- function(x) {
url  = paste0("https://www.ptt.cc", x)
tag  = html_node(read_html(url), 'div#main-content.bbs-screen.bbs-content')
text = toUTF8(html_text(tag))
}
#getContent(data$href[1])
allText = sapply(data$href, getContent)
allText
#out <- file(filename, "w", encoding="BIG-5")
write.table(allText, filename)
#close(out)
}
pttTestFunction(URL[1], filename[1])
source('pttTestFunction.R')
id = c(6128:6125)
URL = paste0("https://www.ptt.cc/bbs/NBA/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
source('pttTestFunction.R')
docs
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
docs
setwd("C:/Users/acer/Desktop/123456/week_2")
mapply(pttTestFunction,
URL = URL, filename = filename)
library(xml2)
library(tmcn)
library(rvest)
pttTestFunction <- function(URL, filename)
{
#URL   = "https://www.ptt.cc/bbs/NTUcourse/index.html"
html  = read_html(URL)
title = html_nodes(html, "a")
href  = html_attr(title, "href")
data = data.frame(title = toUTF8(html_text(title)),
href = href)
data = data[-c(1:10),]
getContent <- function(x) {
url  = paste0("https://www.ptt.cc", x)
tag  = html_node(read_html(url), 'div#main-content.bbs-screen.bbs-content')
text = toUTF8(html_text(tag))
}
#getContent(data$href[1])
allText = sapply(data$href, getContent)
allText
#out <- file(filename, "w", encoding="BIG-5")
write.table(allText, filename)
#close(out)
}
source('pttTestFunction.R')
id = c(6128:6125)
URL = paste0("https://www.ptt.cc/bbs/NBA/index", id, ".html")
filename = paste0(id, ".txt")
pttTestFunction(URL[1], filename[1])
mapply(pttTestFunction,
URL = URL, filename = filename)
#網頁 https://www.ptt.cc/bbs/NBA/index6128.html
#網頁 https://www.ptt.cc/bbs/NBA/index6128.html
#網頁 https://www.ptt.cc/bbs/NBA/index6128.html
#網頁 https://www.ptt.cc/bbs/NBA/index6128.html
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
setwd("C:/Users/acer/Desktop/123456/week_2")
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
rm(list=ls(all.names = TRUE))
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
filenames <- list.files(getwd(), pattern="*.txt")
files <- lapply(filenames, readLines)
docs <- Corpus(VectorSource(files))
#移除可能有問題的符號
toSpace <- content_transformer(function(x, pattern) {
return (gsub(pattern, " ", x))
}
)
docs <- tm_map(docs, toSpace, "※")
docs <- tm_map(docs, toSpace, "◆")
docs <- tm_map(docs, toSpace, "‧")
docs <- tm_map(docs, toSpace, "的")
docs <- tm_map(docs, toSpace, "我")
docs <- tm_map(docs, toSpace, "是")
docs <- tm_map(docs, toSpace, "看板")
docs <- tm_map(docs, toSpace, "作者")
docs <- tm_map(docs, toSpace, "發信站")
docs <- tm_map(docs, toSpace, "批踢踢實業坊")
docs <- tm_map(docs, toSpace, "[a-zA-Z]")
#移除標點符號 (punctuation)
#移除數字 (digits)、空白 (white space)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
docs
mixseg = worker()
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
freqFrame = freqFrame[order(freqFrame$Freq,decreasing=TRUE), ]
library(knitr)
kable(head(freqFrame), format = "markdown")
library(wordcloud)
wordcloud(freqFrame$Var1,freqFrame$Freq,
scale=c(5,0.1),min.freq=50,max.words=150,
random.order=TRUE, random.color=FALSE,
rot.per=.1, colors=brewer.pal(8, "Dark2"),
ordered.colors=FALSE,use.r.layout=FALSE,
fixed.asp=TRUE)
setwd("C:/Users/acer/Desktop/123456/week_2")
